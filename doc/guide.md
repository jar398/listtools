# List tools user guide

See also [philosophy / theory / method](theory.md)

## Overview

The 'tools' or 'scripts' or 'programs' in this repository manipulate
tabular data in the form of CSV files.  Most of them act as filters
and can be invoked from the Unix shell.  They can be sequenced into
pipelines using '|' if desired.  CSV files uniformly have a single
header row giving column names.

I have found it convenient to run the tools by using `make` applied to
a suitable 'makefile'.  This way, intermediate objects can be cached
in the local file system, avoiding expensive regeneration steps when
inputs have not changed.

For my testing I use python 3, `bash`, and GNU `make` exclusively, all
running on Debian Linux.

## Installation
<a name="installation"/>

Python 3, `bash`, and Gnu `make` are all assumed.

Install the python3 `regex` module (although it's easy to revert to
the built-in `re` if you prefer not to).

One of the `Makefile` rules uses `gnparser`, which has download
instructions [here](https://github.com/gnames/gnparser#installation).
`Makefile` assumes that `gnparser` can be located via your shell's `PATH`.
It is easy to remove this dependency if desired, with only a mild
degradation in effectiveness.


## The Makefile

There is no need to use the Makefile since there is no build step for
this project.  However, it contains a variety of canned pipelines for
creating artifacts that are interesting and illustrative.  For example
`make ncbi-report` downloads two versions of the NCBI (Genbank)
taxonomy and produces comparison reports.  It may be helpful to consult
the Makefile for examples of use of the various tools and ideas on how
to string them together.

Read the comments in the [`Makefile`](../Makefile) for other things to try.


## The tools

### start

Any Darwin Core data source should be run through src/start.py first,
for some modest validation and DwC-specific cleaning.

    src/start.py --pk taxonID <foo-raw.tsv >foo.csv

`--pk` specifies the column containing the table's primary keys.  If
there is no such column, one is added, and if a primary key is
missing, a new one is generated by hashing the contents of the row.

Reused putatively-primary keys are detected and flagged.

Data cleaning is performed for the following columns:

 - `canonicalName`, `scientificName` - if a scientific name (with
   authority) is found in the canonicalName column, and the
   `scientificName` column is empty, then the scientific name is moved
   to the `scientificName` column (and so on)
 - `acceptedNameUsageID` - if empty, copy the `taxonID`
 - `taxonomicStatus` - flag if a record with taxonomic status
   `synonym` does not have an accepted taxon id, or if one with status
   `accepted` does
 - `source` - cleanup specific to EOL DH 0.9 and smasher - remove
   source record ids other than the first
 - `Landmark` - recode values, change to `landmark_status` - EOL specific cleanup

`--managed prefix:column` is for designating use of managed identifier
spaces.  If one column contains, say, NCBI taxids, or GBIF taxon
identifiers, or anything similar, that are stable across versions of
the source (as opposed to being idiosyncratic to one version), then
the column should be copied to the `managed_id` column.  This
operation is what this feature is for.  For examples, `--managed
gbif:taxonID` means that the taxonID column contains managed GBIF
taxon 'identifiers' and the `managed_id` column will contain 'managed
identifiers' (an idea I made up).  E.g. if a row's taxonID contains
`359` then the string `gbid:359` will be placed in the `managed_id`
column.  This will then be used for matching operations.


### sortcsv

`sortcsv` sorts standard input by the contents of the given `--pk`
column, and writes the result to standard output.

    src/sortscv.py --pk taxonID <foo.csv >foo-sorted.csv


### project

`project` (emphasis on second syllable) drops columns from the input.
With `--keep`, it drops all columns other than those specified:

    src/project.py --keep a,b,c <foo.csv >less-foo.csv

With `--drop`, it drops particular columns, keeping all the rest:

    src/project.py --drop a,b,c <foo.csv >less-foo.csv


### extract_names

This extracts scientific names in a form suitable for consumption by `gnparse`.


### use_gnparse

This consumes the output of `gnparse` and combines it with the table
that it just processed, enriching the table with the addition of extra
columns that can be used in further analysis.

 * `canonicalName` is added if it is not already present
 * `canonicalStem` is added (see the `gnparse` documentation)
 * `year` is added
 * `type` is added - this is a special string used for matching, and has 
   the form `TS|yyyy|eeeee|aaa` with components generated from
   parsing the scientific name.  `eeeee` is the stemmed version of the _last_ epithet,
   either subspecific, specific, or generic.  `aaa` is supposed to be
   the last name of the first author (but I bet it's sometimes
   wrong). `TS` is supposed to remind us that the string is supposed
   to be associated with the type specimen or type series, and not any
   particular taxon containing them.

Sometimes there are ambiguities, e.g. `TS|1834|typic|Smith` which
seems to derive from numerous distinct species, but usually the `type`
feature is a big help in matching names when the genus assignment changes.


### match_records

Given input checklists A and B, finds the best unique mutual matches
between the A records and the B records.

 * `--A` filename  - the A input.
 * `--B` filename  - the B input.
 * `--pk` K - specify primary key; default `taxonID`
 * `--index` columns names - lists columns to be used for comparison,
      in priority order.

Standard input is the A input, but it can be specified as the B input
by giving `-` as the filename.

The output (to standard output) has these columns:

 - `match_id` - the id of an A record, or empty if the row corresponds
   to an unmatched B record.
 - `relation` - an RCC5 relationship, but really either `=`, `?` (no
   information), or empty (nothing to compare to).
   (Mistake, that ought to be `relationship`.)
 - `taxonID` - the id of a B record, or empty if the row corresponds
   to an unmatched A record.
 - `basis_of_match` - a textual report of what happened, with
   the deciding column name is a match was made, and a diagnostic
   if no match was made and there was a near miss.

If the primary key is specified as something different, the first
three columns reflect what's given.

Records are matched by the values in their 'index' columns, which
should be given in priority order.  That is, if the index columns are
x, y, and z, then an attempt to match records is made first on the
values in the x column.  If either value is missing, or if the
match is ambiguous, then the y column is consulted, and so on.

In the case of an ambiguity, i.e. multiple A records matching a B
record with the same match score or vice versa, none of the records is
matched.  This fact is recorded in the `remark` column of the delta.
A situation like this should provoke manual review; it could mean
that the inputs are ill-formed, or it could mean the scoring algorithm
simply doesn't have enough information to choose between the matches.

The B input should not contain a `mode` column, and if it does, the
column is ignored.

### ncbi_to_dwc

Converts an NCBI taxdmp .zip file to DwC.  For example, suppose we fetch
a zip file and unzip it, e.g.:

    wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/taxdmp_2015-05-01.zip
    unzip -d dump taxdmp_2015-05-01.zip

Then we can convert the dump directory to a single DwC .csv file:

    src/ncbi_to_dwc.py dump >taxdmp_2015-05-01.csv

Columns in the DwC output:
`taxonID`, `NCBI Taxonomy ID`, `parentNameUsageID`, `taxonRank`,
`acceptedNameUsageID`, `scientificName`, `canonicalName`,
`taxonomicStatus`, `nomenclaturalStatus`

### subset

`subset` generates a subset of the rows of a given file, starting from
a specified root.

    src/subset.py --root 40674 <all.csv >some.csv

It assumes the usual Darwin Core hierarchical structure, given by
these columns: 

 - `taxonID` identifies a row (and a taxon, which is probably an extension)
 - `parentNameUsageID` indicates the record for the parent in the hierarchy
 - `acceptedNameUsageID` indicates an accepted name that might replace an
   non-accepted one (although in fact there is more meaning to this attribute).
 - `taxonomicStatus` is `accepted` for an accepted (non-synonym) row, 
   `synonym` for a synonym row

You can specify the root using its `canonicalName` it that's unique:

    src/subset.py --root Mammalia <all.csv >some.csv

### merge

Replaces `align` TBD

### align

Hierarchy alignment, seeded with record matches (`match_records`,
above).  Work in progress.

 - Input files: A; B; A/B record matches (see `match_records`)
 - Standard output: the 'sum' of A and B.
   Columns:
     - `taxonID` - a unique primary key within the output.  Usually but not 
       always either the A taxonID or the B taxonID.
     - `taxonID_A` - a taxonID from the A input file, or empty
     - `taxonID_B` - a taxonID from the B input file, or empty
     - `parentNameUsageID` - a taxonID in the output, or empty at the root(s)
     - `acceptedNameUsageID` - a taxonID in the output, when the row is a synonym.
     - `canonicalName` - this is mainly for debugging and ease of inspection.
       A `canonicalName` copied from the B input, if taxonID_B is present,
       or from the A input otherwise.
     - `remark` - annotation concerning how the alignment was made, or why it wasn't

Invocation:

    src/align.py < A.csv --target B.csv --matches AB_RM.csv > AB.csv

where `AB_RM.csv` was generated by `match_records`.

### report

Input: the output of `merge`.

Two outputs:

 * per-taxon details comparing them between the two inputs, and
 * a summary report breaking down all taxa by the nature of any
   difference.  Here is an example of a summary:

       37      37 accepted/synonym
     1765    1764 canonicalName
       40      40 canonicalName;accepted/synonym
       15      15 canonicalName;synonym/accepted
       17      17 canonicalName;use of name (in A ! in B)
        8       8 canonicalName;use of name (in A < in B)
        2       2 canonicalName;use of name (in A <= in B)
        3       2 canonicalName;use of name (in A > in B)
    18571   18291 not in A
      860     426 not in A;use of name (in A ! in B)
      115      78 not in A;use of name (in A < in B)
        9       0 not in A;use of name (in A <= in B)
      107      68 not in A;use of name (in A > in B)
        5       5 not in A;use of name (in A >= in B)
       58      58 not in A;use of name (in A ? in B)
    12974    2653 not in B
     2349    1617 same
     4322    4322 scientificName
       47      47 scientificName;accepted/synonym
      129     129 scientificName;synonym/accepted
       56      56 synonym/accepted

(This will likely be improved for better readability; but this is what
it looks like today, 12/31/2021.)

The rows in this table are for categories of taxa.  The first column
is the number of taxa (rows, records) in the category.  The second is
the number of species.  The third is a telegraphic description of the
category.  The categories are mutually exclusive.  The description is
a set of differences separated by semicolons.  

 * `same` means no difference detected.
 * `not in A` and `not in B` mean the taxon occurs
   in only one of the two merge inputs, unmatched to any taxon in the
   other.
 * `canonicalName` and `scientificName` give a column in which the two
   records differ.
 * `synonym/accepted` means the taxon is given a synonym in the
   'A' input and an accepted name in the 'B' input; `accepted/synonym`
   is the reverse.
 * `use of name` means that the name (from the second input) is used
 * for a different taxon (extension) in A.  `(in A < in B)`
   means the extension for the name in A is inferred to be smaller
   than that for the same name in B, i.e. the application of the name
   has been 'widened'. 


### newick

An extremely rudimentary Newick notation parser.  

The following
accepts a Newick string on the command line and emits a CSV table with
basic Darwin Core columns:

    $ src/newick.py --newick "(a,b)c"
    taxonID,canonicalName,parentNameUsageID,acceptedNameUsageID,taxonomicStatus
    2,a,1,,accepted
    3,b,1,,accepted
    1,c,,,accepted
    $ 

The following reads CSV (with header row) from standard input and
writes a Newick string to standard output:

    $ cat <<EOF | src/newick.py
    taxonID,canonicalName,parentNameUsageID,acceptedNameUsageID,taxonomicStatus
    2,a,1,,accepted
    3,b,1,,accepted
    1,c,,,accepted
    EOF
    (a,b)c
    $ 

Branch length syntax is not handled.  Newick escape sequences are not handled.

This program supports an idiosyncratic syntax for synonyms (useful
since the main use for this feature is testing): an asterisk `*`
suffixed to a name says that the name is to be considered a synonym
(i.e. not accepted).

### util

This module is not invoked on its own.  It contains a few internal
utilities shared among the various tools.



## Reading the output

I use a few conventions for the progress output generated by the tools:

 - Lines beginning with a run of hyphens `--` are intended to be read by the
   general user, and describe what is going on in terms that ought to
   be easily understood
 - Lines beginning with asterisk `*` have to do with the detection of bugs or
   peculiar or confusing situations that might demand some attention from a developer
 - Lines beginning with a hash `#` are directed at me, and I don't
   expect anyone else to understand them
 - Other lines come from code that I didn't write, such as `make` or `wc`

