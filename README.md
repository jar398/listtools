# listtools
Tools for manipulating lists of things, and taxonomic checklists in particular.

## Overview

The 'tools' or 'scripts' in this repository manipulate tabular data
in the form of CSV files.  Most of them act as filters and can be
invoked from the Unix shell.  They can be sequenced into pipelines
using '|' if desired.

I have found it convenient to run the tools by using `make` applied to
a suitable 'makefile'.  This way, intermediate objects can be cached
in the local file system, avoiding expensive regeneration steps when
an input required for producing such an object changes.

For my testing I use python 3, `bash`, and GNU `make` exclusively.

### Terminology

When I speak of a Darwin core (DwC) file I take this to mean (for
purposes of these tools) a CSV file where each row describes a name
(such as a Linnaean binomial) or a use of a name, in the context of
all the other rows in the same file, and in the context of whatever we
know about the origin of the file itself.  I am calling such things
(names or uses of names) "usages" roughly following "taxonomic name usage"
or TNU, although I don't pretend that "usage" here is as
rigorous a notion as TNU.

The primary key in such files is `taxonID` which is a bit confusing
because the identifier for a usage row doesn't always identify a
taxon: it is connected to a row in the file, and the file may imply
that the row corresponds to a particular taxon, or not.  Multiple
"usages" may correspond to the same taxon, so if we did have a taxon
identifier, it would not identify a usage.  On the other hand, while a
usage identifier (a `taxonID`) always identifies a usage, it may not
be specific enough to identify a particular taxon.

Other Darwin Core columns containing usage identifiers have column
names that contain 'usage' as a morpheme, e.g. `parentNameUsageID`.

Sometimes a given taxonomic name is used in multiple ways in the same
file (homonyms, hemihomonyms, etc.), in which case the usages are
distinguished by their usage identifiers (and the contents of their
respective rows, etc.).

Of course it is desirable that a usage should be interpreted as a
particular taxon or "taxon concept", but often the central problem is
that we don't know which taxon is meant, and we'd like to figure that
out.  At least we know what the usage is.

In the EOL internals, usage rows (records) are called "nodes", but I
avoid this word due to its various conflicting and restricting
meanings, such as for graph database nodes in Neo4J.

### Primary

It's assumed that any file participating in these tools has a column
containing a primary key, i.e. a column that always contains a value,
and a different value for each row.

## The tools

### start

Any Darwin Core data source should be run through src/start.py first,
for some modest validation and DwC-specific cleaning.

    src/start.py --pk taxonID <foo-raw.tsv >foo.csv

`--pk` specifies the column containing the table's primary keys.  If
there is no such column, one is added, and if a primary key is
missing, a new one is generated by hashing the contents of the row.

Reused keys are detected and flagged.

### sortcsv

`sortcsv` sorts standard input by the contents of the given `--pk`
column, and writes the result to standard output.

    src/sortscv.py --pk taxonID <foo.csv >foo-sorted.csv


### project

`project` drops columns from the input.
With `--keep`, it drops all columns other than those specified:

    src/project.py --keep a,b,c <foo.csv >less-foo.csv

With `--drop`, it drops particular columns, keeping all the rest:

    src/project.py --drop a,b,c <foo.csv >less-foo.csv

### match_records

Given input checklists A and B, finds the best unique mutual matches
between the A records and the B records.

    `--target` filename  - the B input.
    `--pk` K - specify primary key; default `taxonID`
    `--index` columns names - lists columns to be used for comparison,
      in priority order.

Standard input is the A input.

The output (to standard output) has these columns:

 - `taxonID` - this is a unique primary key for the row.  If there is
   a B usage given, then this id is the same as that for the B usage.
   If not, it is the A id, if it doesn't conflict with any B id, or
   freshly generated otherwise.
   Always present.
 - `taxonID_A` - the id of an A usage, or empty if the row corresponds
   to an unmatched B usage record.
 - `taxonID_B` - the id of a B usage, or empty if the row corresponds
   to an unmatched A usage record.
 - `remark` - a textual report of what happened, if no match was made.

If the primary key is specified as something different, the first
three columns reflect what's given.

Records are matched by the values in their 'index' columns, which
should be given in priority order.  That is, if the index columns are
x, y, and z, then an attempt to match records is made first on the
values in the x column.  If either value is missing, or if the
match is ambiguous, then the y column is consulted, and so on.

In the case of an ambiguity, i.e. multiple A records matching a B
record with the same match score or vice versa, none of the records is
matched.  This fact is recorded in the `remark` column of the delta.
A situation like this should provoke manual review; it could mean
that the inputs are ill-formed, or it could mean the scoring algorithm
simply doesn't have enough information to choose between the matches.


### delta

`delta` compares two files (call them A and B), matching rows of one
to rows of the other, and generating a "delta" (call it B-A) which
describes the differences between A and B.  A delta is an annotated
report listing all unmatched and changed rows, not including exact row
matches.

    src/delta.py <a.csv --target b.csv \
                        --matches m.csv \
                        --pk y \
                        --index x,y,z \
                        --managed z,y,d,e,f

`--matches` names a file that was generated by `match_records` (or
another tool generating the same kind of file).  If it's omitted then
`match_records` is invoked implicitly.

`--pk` specifies the primary key column for both inputs.

Each row of the delta comes from A only, from B only, or from matched
rows in A and B.  Because of the use of deltas in patching, these
three types of row are given labels `remove`, `add`, and `update` in
the `mode` column of the delta.  The primary key in the delta is taken
from A in the case of `remove` and `update` records.  The primary key
from the B file is given in `new_pk` of the delta.

The output contains only the managed columns (`--manage`), and matched
rows are considered updated only if one of the managed columns
differs.

The matches are done on only a row-by-row basis and are not sensitive
to hierarchy or other sources of meaning.  Usage rows may therefore be
matched even when they must be interpreted as distinct taxa.  Such
distinctions are to be discovered by future independent tools.

### apply

Applies a sorted delta B-A to sorted file A (which typically would be
the A file from which the delta was generated), generating a file B′.
B′ will be projection of B to the given 'managed' columns, with
perhaps the rows in a different order.

    src/apply.py --delta ba.delta --pk taxonID \
                 < a.csv > b2.csv

### scatter

Given a delta, generate a directory containing one file for each of
the three kinds of record in the delta (add, udpate, remove).

    src/scatter.py <delta.csv --dest delta

writes `delta/add.csv`, `delta/update.csv`, `delta/remove.csv`.  These
can be fed to appropriate database commands to incrementally update a
database to a new version of a table.

### subset

`subset` generates a subset of the rows of a given file, starting from
a specified root.  It assumes the usual Darwin Core hierarchical
structure: `taxonID` identifies a usage row, `parentNameUsageID`
indicates the usage row for the parent in the hierarchy, and
`acceptedNameUsageID` indicates an accepted usage that can replace
an non-accepted one.

    src/subset.py --root 40674 <all.csv >some.csv

### hierarchy

This is specific to EOL.  It applies a usage id to page id mapping
(in a file named by an argument) to a file full of usages to generate a file
with one row per page, giving the parent of each page.

The resulting page list can be subjected to `delta` and `scatter` to
incrementally update an in-database hierarchy, etc.

### ncbi_to_dwc

Converts an NCBI taxdmp .zip file to DwC.  For example, suppose we fetch
a zip file and unzip it, e.g.:

    wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/taxdmp_2015-05-01.zip
    unzip -d dump taxdmp_2015-05-01.zip

Then we can convert the dump directory to a single DwC .csv file:

    src/ncbi_to_dwc.py dump >taxdmp_2015-05-01.csv

### util

This module is not invoked on its own, but just contains a few
internal utilities shared among the various tools.


## Demos

`make` will compare the mammals in two versions of NCBI Taxonomy.
Read the comments in the `Makefile` for other things to try.

## Reading the output

I use a few conventions for the progress output generated by the tools:

 - Lines beginning with a run of hyphens `--` are intended to be read by the
   general user, and describe what is going on in terms that ought to
   be easily understood
 - Lines beginning with asterisk `*` have to do with the detection of bugs or
   peculiar or confusing situations that might demand some attention
 - Lines beginning with a hash `#` are directed at me, and I don't
   expect anyone else to understand them
 - Other lines come from code that I didn't write, such as `make` or `wc`


## Configuration for EOL

For EOL, the list tools are intended to be used in conjunction with
`plotter`, which provides access to file repositories such as
`content.eol.org` and other sources of EOL information.

Configure `plotter` according to its documentation.  Then, assuming
the `plotter` repository is cloned in directory `../plotter`, do the
following in your `listtools` working directory:

    ln -sfT ../plotter/config config

Depending on the location of `plotter` and the directory where you're
working, adjust the above command, and also update `Makefile` where it
mentions `plotter`.
