#!/usr/bin/env python3

# Make use of the output of gnparse, by adding new columns to the checklist

import sys, csv, argparse
import regex
import util, parse
from util import windex, MISSING, log

# was auth_re = re.compile("[A-Z][A-Za-z'-]+")
auth_re = regex.compile(u"\\p{Uppercase_Letter}[\\p{Letter}-]+")
year_re = regex.compile(' ([12][0-9]{3})\\)?$')

CANON_SAMPLE_LIMIT = 0    # for debugging
ADD_TIPES = True

# Returns a generator

def use_gnparse(gn_iter, check_iter):

  # gnparse output: gn_iter / gn_header
  gn_header = next(gn_iter)
  # Id,Verbatim,Cardinality,CanonicalStem,CanonicalSimple,CanonicalFull,Authorship,Year,Quality
  if len(gn_header) != 9:
    log("** Expected 9 columns in gnparse output, but got %s" % (len(gn_header),))
    assert False
  verbatim_pos = windex(gn_header, "Verbatim")
  cardinality_pos = windex(gn_header, "Cardinality")
  canonical_stem_pos = windex(gn_header, "CanonicalStem")
  canonical_full_pos = windex(gn_header, "CanonicalFull")
  canonical_simple_pos = windex(gn_header, "CanonicalSimple")
  auth_pos = windex(gn_header, "Authorship")
  year_pos = windex(gn_header, "Year")
  quality_pos = windex(gn_header, "Quality")

  checklist_header = next(check_iter)
  out_header = checklist_header + []

  def ensure_column(col):
    pos = windex(out_header, col)
    if pos != None:
      return (pos, False)
    else:
      pos = len(out_header)
      out_header.append(col)
      return (pos, True)      

  # Add gn_full, gn_stem, gn_auth
  (out_gn_full_pos, add_gn_full) = ensure_column("gn_canonical_full")
  (out_gn_stem_pos, add_gn_stem) = ensure_column("gn_canonical_stem")
  (out_gn_auth_pos, add_gn_auth) = ensure_column("gn_authorship")
  (out_canon_pos, add_canon) = ensure_column("canonicalName")
  (out_sci_pos, add_sci) = ensure_column("scientificName")

  # May need to consult the source record too
  scientific_pos = windex(checklist_header, "scientificName")
  canonical_pos = windex(checklist_header, "canonicalName")
  taxonid_pos = windex(checklist_header, "taxonID")

  n_added_columns = (len(out_header) - len(checklist_header))

  row_count = 0
  loser_count = 0

  yield out_header
  for checklist_row in check_iter:
    assert len(checklist_row) == len(checklist_header)
    row_count += 1
    gn_row = next(gn_iter)
    out_row = checklist_row + n_added_columns*[MISSING]

    # Kludge to allow gnparse to parse names of the form '? foo'
    gn_full = fix_question_mark(gn_row[canonical_full_pos])
    gn_stem = fix_question_mark(gn_row[canonical_stem_pos])
    gn_verb = fix_question_mark(gn_row[verbatim_pos])
    gn_auth = fix_question_mark(gn_row[auth_pos])

    if gn_full.endswith('ii') and gn_stem.endswith('i'):
      # Fixed in gnparse, but I'm still using older version
      gn_stem = gn_stem[0:-1]

    if out_row[out_canon_pos] == MISSING:
      out_row[out_canon_pos] = gn_full
    if out_row[out_sci_pos] == MISSING:
      out_row[out_sci_pos] = gn_verb

    out_row[out_gn_full_pos] = gn_full
    out_row[out_gn_stem_pos] = gn_stem
    out_row[out_gn_auth_pos] = gn_auth

    q = int(gn_row[quality_pos])
    if gn_full == MISSING or gn_stem == MISSING or q >= 4:
      if q > 0:                 # e.g. BOLD:ACH7315
        log("** %s: Ill-formed name: '%s'" %
            (checklist_row[taxonid_pos], gn_verb))
      loser_count += 1
    yield out_row

  if loser_count > 0:
    log("-- %s rows with poor gnparser quality" % loser_count)

  log("-- use_gnparse: %s rows" % (row_count,))

def fix_question_mark(s):
  if s.startswith('Xyzzy'):
    s = '?' + s[5:]
  return s.replace('xyzzy', '?')

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description="""
    Standard input is the output generated by `gnparse -s` for a set of
    'scientific names.'
    Standard output is formed by combining the gnparse output with the
    parallel set of rows from the SOURCE Darwin Core checklist to 
    form a new checklist with a few additional columns.
    """)
  parser.add_argument('--source',
                      help="name of file containing checklist")
  args=parser.parse_args()
  assert args.source
  gn_file = sys.stdin
  with open(args.source, "r") as source_file:
    # rows is a generator
    rows = use_gnparse(csv.reader(gn_file),
                       csv.reader(source_file))
    util.write_rows(rows, sys.stdout)
