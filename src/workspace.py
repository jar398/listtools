#!/usr/bin/env python3

import sys, csv
from typing import NamedTuple, Any

import property as prop
import checklist

from util import log
from checklist import *
from coproduct import *

# -----------------------------------------------------------------------------
# Sum / coproduct / merged checklist / theory workspace
# Could be either just the matches (not a checklist), or the matches
# plus overrides (synthetic checklist)

# Returns B side

def make_workspace(A, B):
  Q = prop.make_context()       # allows overriding A and/or B
  (get_inject, set_inject) = prop.get_set(inject_prop, context=Q)

  def ensure_injected(x):
    z = get_inject(x, None)
    if not z:
      z = prop.clone(x)
      set_inject(x, z)          # contextual
      set_outject(z, x)
      # Every node starts out being a child of ‚ä§
      set_superior(z, AB.topship)
      checklist.set_source(z, AB)
    return z

  def _in_left(x):
    assert checklist.get_source(x) == A
    return ensure_injected(x)
  def _in_right(y):
    assert checklist.get_source(y) == B
    return ensure_injected(y)
  def _case(z, when_left, when_right):
    w = get_outject(z)
    if checklist.get_source(w) == A:
      return when_left(w)
    else:
      assert checklist.get_source(w) == B
      return when_right(w)
  AB = Coproduct(_in_left, _in_right, _case)
  AB.context = Q
  AB.top = make_top(AB)
  AB.topship = Related(LT, AB.top, "uninitialized")

  AB.A = A           # need ??
  AB.B = B

  return AB

# -----------------------------------------------------------------------------
# Load/dump a set of equivalences (could be either record match or taxonomic match)

# Fields of match records <A (equivalentID), B (taxonID), remark>
equivalent_key_prop = prop.get_property("equivalentID")
equivalence_note_prop = prop.get_property("equivalence_note")
get_equivalent_key = prop.getter(equivalent_key_prop)

# Property of workspace records
equivalent_prop = prop.get_property("equivalent")
(get_equivalence_note, set_equivalence_note) = \
    prop.get_set(equivalence_note_prop)

def load_equivalences(row_iterator, AB):

  header = next(iterator)
  plan = prop.make_plan_from_header(header)
  for row in row_iterator:
    # [equivalent taxonID remark]
    match = prop.construct(plan, row)

    # The three columns of the csv file
    xkey = get_equivalent_key(match, None)
    ykey = get_primary_key(match, None)
    remark = get_equivalence_note(match)

    x = y = None
    if xkey:
      x_in_A = look_up_record(AB.A, xkey)
      if x_in_A:
        x = AB.in_left(x_in_A)
        AB.set_equivalence_note(x, remark)
    if ykey:
      y_in_B = look_up_record(AB.B, ykey)
      if y_in_B:
        y = AB.in_right(y_in_B) 
        AB.set_equivalence_note(y, remark)
    if x and y:
      set_equivalent(x, y)
      set_equivalent(y, x)

"""
TBD: filter out seniors
  seniors = 0
      # Filter out senior synonyms here
      if is_senior(item, accepted_item):
        seniors += 1
      else:
  if seniors > 0:     # Maybe interesting
    print("-- Suppressed %s senior synonyms" % seniors,
          file=sys.stderr)

"""

def assign_primary_keys(AB):
  counter = [1]
  set_primary_key = prop.setter(primary_key_prop, context=AB.context)
  register = prop.get_registrar(primary_key_prop, AB.context)

  def process(x, z):
    if is_top(z):
      pass
    elif get_superior(z, None).relation == LE and is_senior(z, get_accepted(z)):
      pass
    else:
      key = str(counter[0])
      set_primary_key(z, key)
      register(z)
      counter[0] += 1

  for x in all_records(AB.A):
    if get_equivalent(x, None):
      # (should add a synonym record if canonical differs ...)
      pass
    else:
      process(x, AB.in_left(x))
  for y in all_records(AB.B):
    process(y, AB.in_right(y))

  log("> %s taxonIDs assigned" % counter[0])

# Is given synonym usage a senior synonym of its accepted usage?
# In the case of splitting, we expect the synonym to be a senior
# synonym of the item.

# We could also look to see if taxonomicStatus is 'senior synonym'.

# Hmm, if there's exactly one senior synonym, we should remember it as
# being the 'split from' taxon.

def is_senior(synonym_item, accepted_item):
  syn_year = get_year(synonym_item, None)  # the synonym
  acc_year = get_year(accepted_item, None)
  if syn_year and acc_year:
    # Older name (senior) has priority over newer (junior)
    # but if junior is accepted we don't care about the senior.
    if syn_year <= acc_year:
      # synonym is older than accepted, so syn > acc.  Shouldn't
      # happen.  (these are generated by MDD)
      print("# Flushing senior synonym '%s' of '%s'" %
            (get_scientific(synonym_item),
             get_scientific(accepted_item)))
      return True
    else:
      # synonym is newer than accepted, so syn < acc.  Junior.
      #  (split)
      return False
  else:
    return False


# -----------------------------------------------------------------------------

if __name__ == '__main__':
  import newick

  def testit(m, n):
    A = rows_to_checklist(newick.parse_newick(m),
                          {"name": "A"})  # meta
    B = rows_to_checklist(newick.parse_newick(n),
                          {"name": "B"})  # meta
    AB = make_workspace(A, B)
    assign_primary_keys(AB)
    collect_inferiors(AB)
    writer = csv.writer(sys.stdout)
    rows = list(checklist_to_rows(AB))
    for row in rows:
      writer.writerow(row)
    print(newick.compose_newick(rows))

  testit("a", "b")
